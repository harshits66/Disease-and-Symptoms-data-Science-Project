{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c11fc760-0c9f-4907-9cac-da095d23171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ebd1fe5-b21a-4acc-a8c3-0a7c80e58f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('disease.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f929d6-ee53-44b8-89df-3a0797e95e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4920 entries, 0 to 4919\n",
      "Data columns (total 18 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Disease     4920 non-null   object\n",
      " 1   Symptom_1   4920 non-null   object\n",
      " 2   Symptom_2   4920 non-null   object\n",
      " 3   Symptom_3   4920 non-null   object\n",
      " 4   Symptom_4   4572 non-null   object\n",
      " 5   Symptom_5   3714 non-null   object\n",
      " 6   Symptom_6   2934 non-null   object\n",
      " 7   Symptom_7   2268 non-null   object\n",
      " 8   Symptom_8   1944 non-null   object\n",
      " 9   Symptom_9   1692 non-null   object\n",
      " 10  Symptom_10  1512 non-null   object\n",
      " 11  Symptom_11  1194 non-null   object\n",
      " 12  Symptom_12  744 non-null    object\n",
      " 13  Symptom_13  504 non-null    object\n",
      " 14  Symptom_14  306 non-null    object\n",
      " 15  Symptom_15  240 non-null    object\n",
      " 16  Symptom_16  192 non-null    object\n",
      " 17  Symptom_17  72 non-null     object\n",
      "dtypes: object(18)\n",
      "memory usage: 692.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d0d6109-25f0-421a-b91c-190036037168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode diseases\n",
    "le_disease = LabelEncoder()\n",
    "df['Disease'] = le_disease.fit_transform(df['Disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b829bb-7704-48bc-a25d-c2c66e8db405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4920 entries, 0 to 4919\n",
      "Data columns (total 18 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Disease     4920 non-null   int32 \n",
      " 1   Symptom_1   4920 non-null   object\n",
      " 2   Symptom_2   4920 non-null   object\n",
      " 3   Symptom_3   4920 non-null   object\n",
      " 4   Symptom_4   4572 non-null   object\n",
      " 5   Symptom_5   3714 non-null   object\n",
      " 6   Symptom_6   2934 non-null   object\n",
      " 7   Symptom_7   2268 non-null   object\n",
      " 8   Symptom_8   1944 non-null   object\n",
      " 9   Symptom_9   1692 non-null   object\n",
      " 10  Symptom_10  1512 non-null   object\n",
      " 11  Symptom_11  1194 non-null   object\n",
      " 12  Symptom_12  744 non-null    object\n",
      " 13  Symptom_13  504 non-null    object\n",
      " 14  Symptom_14  306 non-null    object\n",
      " 15  Symptom_15  240 non-null    object\n",
      " 16  Symptom_16  192 non-null    object\n",
      " 17  Symptom_17  72 non-null     object\n",
      "dtypes: int32(1), object(17)\n",
      "memory usage: 672.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c82c575a-ab5f-412e-899c-cf2961ac87bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode symptoms\n",
    "all_symptoms = df.columns[1:]\n",
    "le_symptoms = LabelEncoder()\n",
    "for symptom in all_symptoms:\n",
    "    df[symptom] = le_symptoms.fit_transform(df[symptom].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "595f9172-46ad-4e6a-9df4-5519d7ed13e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix X and target vector y\n",
    "X = df.drop('Disease', axis=1)\n",
    "y = df['Disease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfe2367f-dc2d-4d68-89af-9fbea2af7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5511678-52c1-4835-b713-5bb1f894fc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Apply various ML algorithms\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'k-NN': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Neural Network': MLPClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21d05e78-e74b-4eb9-b9d8-f4e592dfdb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9288617886178862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        18\n",
      "           1       0.67      0.53      0.59        30\n",
      "           2       0.50      0.79      0.61        24\n",
      "           3       1.00      1.00      1.00        25\n",
      "           4       0.60      1.00      0.75        24\n",
      "           5       1.00      0.78      0.88        23\n",
      "           6       1.00      1.00      1.00        33\n",
      "           7       1.00      0.87      0.93        23\n",
      "           8       1.00      1.00      1.00        21\n",
      "           9       1.00      1.00      1.00        15\n",
      "          10       1.00      1.00      1.00        23\n",
      "          11       1.00      1.00      1.00        26\n",
      "          12       1.00      1.00      1.00        21\n",
      "          13       1.00      0.86      0.93        29\n",
      "          14       1.00      0.67      0.80        24\n",
      "          15       0.70      0.84      0.76        19\n",
      "          16       1.00      1.00      1.00        28\n",
      "          17       0.81      0.84      0.82        25\n",
      "          18       1.00      0.74      0.85        23\n",
      "          19       1.00      1.00      1.00        27\n",
      "          20       0.81      1.00      0.90        26\n",
      "          21       1.00      1.00      1.00        23\n",
      "          22       1.00      1.00      1.00        29\n",
      "          23       1.00      1.00      1.00        25\n",
      "          24       1.00      1.00      1.00        24\n",
      "          25       1.00      1.00      1.00        26\n",
      "          26       1.00      1.00      1.00        21\n",
      "          27       0.90      0.79      0.84        24\n",
      "          28       1.00      1.00      1.00        19\n",
      "          29       1.00      1.00      1.00        22\n",
      "          30       1.00      1.00      1.00        25\n",
      "          31       1.00      1.00      1.00        22\n",
      "          32       0.71      0.62      0.67        24\n",
      "          33       1.00      1.00      1.00        17\n",
      "          34       1.00      1.00      1.00        28\n",
      "          35       1.00      0.86      0.93        22\n",
      "          36       1.00      1.00      1.00        25\n",
      "          37       1.00      1.00      1.00        19\n",
      "          38       1.00      1.00      1.00        26\n",
      "          39       1.00      1.00      1.00        22\n",
      "          40       1.00      1.00      1.00        34\n",
      "\n",
      "    accuracy                           0.93       984\n",
      "   macro avg       0.94      0.93      0.93       984\n",
      "weighted avg       0.94      0.93      0.93       984\n",
      "\n",
      "\n",
      "Decision Tree Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00        30\n",
      "           2       1.00      1.00      1.00        24\n",
      "           3       1.00      1.00      1.00        25\n",
      "           4       1.00      1.00      1.00        24\n",
      "           5       1.00      1.00      1.00        23\n",
      "           6       1.00      1.00      1.00        33\n",
      "           7       1.00      1.00      1.00        23\n",
      "           8       1.00      1.00      1.00        21\n",
      "           9       1.00      1.00      1.00        15\n",
      "          10       1.00      1.00      1.00        23\n",
      "          11       1.00      1.00      1.00        26\n",
      "          12       1.00      1.00      1.00        21\n",
      "          13       1.00      1.00      1.00        29\n",
      "          14       1.00      1.00      1.00        24\n",
      "          15       1.00      1.00      1.00        19\n",
      "          16       1.00      1.00      1.00        28\n",
      "          17       1.00      1.00      1.00        25\n",
      "          18       1.00      1.00      1.00        23\n",
      "          19       1.00      1.00      1.00        27\n",
      "          20       1.00      1.00      1.00        26\n",
      "          21       1.00      1.00      1.00        23\n",
      "          22       1.00      1.00      1.00        29\n",
      "          23       1.00      1.00      1.00        25\n",
      "          24       1.00      1.00      1.00        24\n",
      "          25       1.00      1.00      1.00        26\n",
      "          26       1.00      1.00      1.00        21\n",
      "          27       1.00      1.00      1.00        24\n",
      "          28       1.00      1.00      1.00        19\n",
      "          29       1.00      1.00      1.00        22\n",
      "          30       1.00      1.00      1.00        25\n",
      "          31       1.00      1.00      1.00        22\n",
      "          32       1.00      1.00      1.00        24\n",
      "          33       1.00      1.00      1.00        17\n",
      "          34       1.00      1.00      1.00        28\n",
      "          35       1.00      1.00      1.00        22\n",
      "          36       1.00      1.00      1.00        25\n",
      "          37       1.00      1.00      1.00        19\n",
      "          38       1.00      1.00      1.00        26\n",
      "          39       1.00      1.00      1.00        22\n",
      "          40       1.00      1.00      1.00        34\n",
      "\n",
      "    accuracy                           1.00       984\n",
      "   macro avg       1.00      1.00      1.00       984\n",
      "weighted avg       1.00      1.00      1.00       984\n",
      "\n",
      "\n",
      "Random Forest Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00        30\n",
      "           2       1.00      1.00      1.00        24\n",
      "           3       1.00      1.00      1.00        25\n",
      "           4       1.00      1.00      1.00        24\n",
      "           5       1.00      1.00      1.00        23\n",
      "           6       1.00      1.00      1.00        33\n",
      "           7       1.00      1.00      1.00        23\n",
      "           8       1.00      1.00      1.00        21\n",
      "           9       1.00      1.00      1.00        15\n",
      "          10       1.00      1.00      1.00        23\n",
      "          11       1.00      1.00      1.00        26\n",
      "          12       1.00      1.00      1.00        21\n",
      "          13       1.00      1.00      1.00        29\n",
      "          14       1.00      1.00      1.00        24\n",
      "          15       1.00      1.00      1.00        19\n",
      "          16       1.00      1.00      1.00        28\n",
      "          17       1.00      1.00      1.00        25\n",
      "          18       1.00      1.00      1.00        23\n",
      "          19       1.00      1.00      1.00        27\n",
      "          20       1.00      1.00      1.00        26\n",
      "          21       1.00      1.00      1.00        23\n",
      "          22       1.00      1.00      1.00        29\n",
      "          23       1.00      1.00      1.00        25\n",
      "          24       1.00      1.00      1.00        24\n",
      "          25       1.00      1.00      1.00        26\n",
      "          26       1.00      1.00      1.00        21\n",
      "          27       1.00      1.00      1.00        24\n",
      "          28       1.00      1.00      1.00        19\n",
      "          29       1.00      1.00      1.00        22\n",
      "          30       1.00      1.00      1.00        25\n",
      "          31       1.00      1.00      1.00        22\n",
      "          32       1.00      1.00      1.00        24\n",
      "          33       1.00      1.00      1.00        17\n",
      "          34       1.00      1.00      1.00        28\n",
      "          35       1.00      1.00      1.00        22\n",
      "          36       1.00      1.00      1.00        25\n",
      "          37       1.00      1.00      1.00        19\n",
      "          38       1.00      1.00      1.00        26\n",
      "          39       1.00      1.00      1.00        22\n",
      "          40       1.00      1.00      1.00        34\n",
      "\n",
      "    accuracy                           1.00       984\n",
      "   macro avg       1.00      1.00      1.00       984\n",
      "weighted avg       1.00      1.00      1.00       984\n",
      "\n",
      "\n",
      "SVM Accuracy: 0.9695121951219512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        18\n",
      "           1       1.00      1.00      1.00        30\n",
      "           2       0.87      0.83      0.85        24\n",
      "           3       1.00      1.00      1.00        25\n",
      "           4       0.92      0.96      0.94        24\n",
      "           5       1.00      1.00      1.00        23\n",
      "           6       1.00      0.97      0.98        33\n",
      "           7       1.00      0.87      0.93        23\n",
      "           8       1.00      1.00      1.00        21\n",
      "           9       1.00      1.00      1.00        15\n",
      "          10       1.00      1.00      1.00        23\n",
      "          11       1.00      1.00      1.00        26\n",
      "          12       1.00      1.00      1.00        21\n",
      "          13       1.00      1.00      1.00        29\n",
      "          14       0.95      0.88      0.91        24\n",
      "          15       0.80      0.84      0.82        19\n",
      "          16       1.00      1.00      1.00        28\n",
      "          17       0.68      0.92      0.78        25\n",
      "          18       1.00      0.74      0.85        23\n",
      "          19       1.00      1.00      1.00        27\n",
      "          20       1.00      1.00      1.00        26\n",
      "          21       1.00      1.00      1.00        23\n",
      "          22       1.00      1.00      1.00        29\n",
      "          23       0.96      1.00      0.98        25\n",
      "          24       1.00      1.00      1.00        24\n",
      "          25       1.00      1.00      1.00        26\n",
      "          26       1.00      1.00      1.00        21\n",
      "          27       0.83      1.00      0.91        24\n",
      "          28       1.00      1.00      1.00        19\n",
      "          29       1.00      1.00      1.00        22\n",
      "          30       1.00      1.00      1.00        25\n",
      "          31       1.00      1.00      1.00        22\n",
      "          32       0.95      0.79      0.86        24\n",
      "          33       1.00      0.94      0.97        17\n",
      "          34       1.00      1.00      1.00        28\n",
      "          35       1.00      0.95      0.98        22\n",
      "          36       1.00      1.00      1.00        25\n",
      "          37       1.00      1.00      1.00        19\n",
      "          38       1.00      1.00      1.00        26\n",
      "          39       1.00      1.00      1.00        22\n",
      "          40       1.00      1.00      1.00        34\n",
      "\n",
      "    accuracy                           0.97       984\n",
      "   macro avg       0.97      0.97      0.97       984\n",
      "weighted avg       0.97      0.97      0.97       984\n",
      "\n",
      "\n",
      "k-NN Accuracy: 0.991869918699187\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00        30\n",
      "           2       0.86      1.00      0.92        24\n",
      "           3       1.00      1.00      1.00        25\n",
      "           4       1.00      1.00      1.00        24\n",
      "           5       1.00      1.00      1.00        23\n",
      "           6       1.00      1.00      1.00        33\n",
      "           7       1.00      1.00      1.00        23\n",
      "           8       1.00      1.00      1.00        21\n",
      "           9       1.00      1.00      1.00        15\n",
      "          10       1.00      1.00      1.00        23\n",
      "          11       1.00      1.00      1.00        26\n",
      "          12       0.84      1.00      0.91        21\n",
      "          13       1.00      1.00      1.00        29\n",
      "          14       1.00      1.00      1.00        24\n",
      "          15       1.00      1.00      1.00        19\n",
      "          16       1.00      1.00      1.00        28\n",
      "          17       1.00      1.00      1.00        25\n",
      "          18       1.00      1.00      1.00        23\n",
      "          19       1.00      1.00      1.00        27\n",
      "          20       1.00      1.00      1.00        26\n",
      "          21       1.00      1.00      1.00        23\n",
      "          22       1.00      1.00      1.00        29\n",
      "          23       1.00      1.00      1.00        25\n",
      "          24       1.00      1.00      1.00        24\n",
      "          25       1.00      1.00      1.00        26\n",
      "          26       1.00      1.00      1.00        21\n",
      "          27       1.00      0.83      0.91        24\n",
      "          28       1.00      1.00      1.00        19\n",
      "          29       1.00      1.00      1.00        22\n",
      "          30       1.00      1.00      1.00        25\n",
      "          31       1.00      1.00      1.00        22\n",
      "          32       1.00      1.00      1.00        24\n",
      "          33       1.00      1.00      1.00        17\n",
      "          34       1.00      1.00      1.00        28\n",
      "          35       1.00      1.00      1.00        22\n",
      "          36       1.00      0.84      0.91        25\n",
      "          37       1.00      1.00      1.00        19\n",
      "          38       1.00      1.00      1.00        26\n",
      "          39       1.00      1.00      1.00        22\n",
      "          40       1.00      1.00      1.00        34\n",
      "\n",
      "    accuracy                           0.99       984\n",
      "   macro avg       0.99      0.99      0.99       984\n",
      "weighted avg       0.99      0.99      0.99       984\n",
      "\n",
      "\n",
      "Naive Bayes Accuracy: 0.8780487804878049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.56      0.65        18\n",
      "           1       1.00      0.73      0.85        30\n",
      "           2       0.76      0.92      0.83        24\n",
      "           3       1.00      1.00      1.00        25\n",
      "           4       0.50      0.96      0.66        24\n",
      "           5       1.00      0.52      0.69        23\n",
      "           6       1.00      0.88      0.94        33\n",
      "           7       0.47      0.61      0.53        23\n",
      "           8       1.00      1.00      1.00        21\n",
      "           9       1.00      0.87      0.93        15\n",
      "          10       1.00      1.00      1.00        23\n",
      "          11       1.00      1.00      1.00        26\n",
      "          12       1.00      1.00      1.00        21\n",
      "          13       1.00      0.79      0.88        29\n",
      "          14       1.00      0.67      0.80        24\n",
      "          15       0.70      0.84      0.76        19\n",
      "          16       1.00      0.93      0.96        28\n",
      "          17       1.00      1.00      1.00        25\n",
      "          18       0.44      0.87      0.59        23\n",
      "          19       1.00      1.00      1.00        27\n",
      "          20       0.85      0.88      0.87        26\n",
      "          21       1.00      0.61      0.76        23\n",
      "          22       1.00      0.93      0.96        29\n",
      "          23       1.00      0.68      0.81        25\n",
      "          24       1.00      1.00      1.00        24\n",
      "          25       0.87      1.00      0.93        26\n",
      "          26       1.00      0.90      0.95        21\n",
      "          27       0.71      0.71      0.71        24\n",
      "          28       0.95      1.00      0.97        19\n",
      "          29       0.69      1.00      0.81        22\n",
      "          30       1.00      0.92      0.96        25\n",
      "          31       1.00      0.86      0.93        22\n",
      "          32       0.69      0.83      0.75        24\n",
      "          33       1.00      0.94      0.97        17\n",
      "          34       1.00      1.00      1.00        28\n",
      "          35       1.00      0.77      0.87        22\n",
      "          36       1.00      1.00      1.00        25\n",
      "          37       1.00      1.00      1.00        19\n",
      "          38       0.84      0.81      0.82        26\n",
      "          39       1.00      0.91      0.95        22\n",
      "          40       1.00      1.00      1.00        34\n",
      "\n",
      "    accuracy                           0.88       984\n",
      "   macro avg       0.91      0.88      0.88       984\n",
      "weighted avg       0.91      0.88      0.88       984\n",
      "\n",
      "\n",
      "Neural Network Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00        30\n",
      "           2       1.00      1.00      1.00        24\n",
      "           3       1.00      1.00      1.00        25\n",
      "           4       1.00      1.00      1.00        24\n",
      "           5       1.00      1.00      1.00        23\n",
      "           6       1.00      1.00      1.00        33\n",
      "           7       1.00      1.00      1.00        23\n",
      "           8       1.00      1.00      1.00        21\n",
      "           9       1.00      1.00      1.00        15\n",
      "          10       1.00      1.00      1.00        23\n",
      "          11       1.00      1.00      1.00        26\n",
      "          12       1.00      1.00      1.00        21\n",
      "          13       1.00      1.00      1.00        29\n",
      "          14       1.00      1.00      1.00        24\n",
      "          15       1.00      1.00      1.00        19\n",
      "          16       1.00      1.00      1.00        28\n",
      "          17       1.00      1.00      1.00        25\n",
      "          18       1.00      1.00      1.00        23\n",
      "          19       1.00      1.00      1.00        27\n",
      "          20       1.00      1.00      1.00        26\n",
      "          21       1.00      1.00      1.00        23\n",
      "          22       1.00      1.00      1.00        29\n",
      "          23       1.00      1.00      1.00        25\n",
      "          24       1.00      1.00      1.00        24\n",
      "          25       1.00      1.00      1.00        26\n",
      "          26       1.00      1.00      1.00        21\n",
      "          27       1.00      1.00      1.00        24\n",
      "          28       1.00      1.00      1.00        19\n",
      "          29       1.00      1.00      1.00        22\n",
      "          30       1.00      1.00      1.00        25\n",
      "          31       1.00      1.00      1.00        22\n",
      "          32       1.00      1.00      1.00        24\n",
      "          33       1.00      1.00      1.00        17\n",
      "          34       1.00      1.00      1.00        28\n",
      "          35       1.00      1.00      1.00        22\n",
      "          36       1.00      1.00      1.00        25\n",
      "          37       1.00      1.00      1.00        19\n",
      "          38       1.00      1.00      1.00        26\n",
      "          39       1.00      1.00      1.00        22\n",
      "          40       1.00      1.00      1.00        34\n",
      "\n",
      "    accuracy                           1.00       984\n",
      "   macro avg       1.00      1.00      1.00       984\n",
      "weighted avg       1.00      1.00      1.00       984\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Evaluate and compare\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "    print(f\"{name} Accuracy: {accuracy}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c01d0dbb-529f-429c-9807-f8fea9e27c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9288617886178862\n",
      "Decision Tree Accuracy: 1.0\n",
      "Random Forest Accuracy: 1.0\n",
      "SVM Accuracy: 0.9695121951219512\n",
      "k-NN Accuracy: 0.991869918699187\n",
      "Naive Bayes Accuracy: 0.8780487804878049\n",
      "Neural Network Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "    print(f\"{name} Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff526e5c-1d77-40fa-b9a7-ced962e9a9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899a64d5-7d4e-4938-931a-ad652b5a481b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
